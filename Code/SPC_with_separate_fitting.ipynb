{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%capture\n",
    "import scipy.io\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "block1 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block001_ICA_based_grad.mat')\n",
    "\n",
    "block2 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block002_ICA_based_grad.mat')\n",
    "block2['spikeind'][0,:] += 600_000\n",
    "spikes = block1['spikeind'][0,:].tolist() + block2['spikeind'][0,:].tolist()\n",
    "\n",
    "tsss_file = \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "data = mne.io.read_raw_fif(tsss_file, preload=False, verbose=False)\n",
    "first_sample = data.first_samp\n",
    "\n",
    "for_conc = []\n",
    "for time in spikes:\n",
    "    t_min = (first_sample + time - 200)/1000\n",
    "    t_max = (first_sample + time + 200)/1000\n",
    "    for_conc.append(data.copy().crop(t_min,t_max))\n",
    "    \n",
    "epochs = mne.concatenate_raws(for_conc)    \n",
    "epochs.annotations.delete(range(len(epochs.annotations)))\n",
    "epochs.load_data().pick_types(meg=True, eeg=False, eog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib qt5\n",
    "%matplotlib qt5\n",
    "\n",
    "\n",
    "plot_sensors = 'grad' # 'mag', 'grad' or True (all sensors)\n",
    "window = 10 #in seconds\n",
    "start = 0.0 #start point in seconds\n",
    "\n",
    "block1 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block001_ICA_based_grad.mat')\n",
    "\n",
    "block2 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block002_ICA_based_grad.mat')\n",
    "block2['spikeind'][0,:] += 600_000\n",
    "spikes = block1['spikeind'][0,:].tolist() + block2['spikeind'][0,:].tolist()\n",
    "\n",
    "\n",
    "data = mne.io.read_raw_fif( \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\", preload=False, verbose=False)\n",
    "#data.pick_types(meg=plot_sensors, eeg=False,stim=False,eog=False,ecg=False,emg=False,misc=False)\n",
    "\n",
    "onset = [(data.first_samp+i)/1000 for i in spikes]\n",
    "data.annotations.append(onset, np.repeat(0.00001, len(onset)), [' ']*len(onset))\n",
    "\n",
    "data.plot(duration=window, group_by='position', start=start, lowpass=100, highpass=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epochs(raw_filt, detections, tmin=-1, tmax=1, picks_raw=True):\n",
    "    \"\"\" Here we create epochs for events\"\"\"\n",
    "    import mne\n",
    "    import numpy as np\n",
    "    eve_id = 1\n",
    "    eve_name = 'ICA_det'\n",
    "    \n",
    "\n",
    "    raw_filt.load_data()\n",
    "    \n",
    "    new_events, eve = [], []\n",
    "    first_samp = raw_filt.first_samp\n",
    "\n",
    "    for spike_time in detections:\n",
    "        eve = [int(round(spike_time + first_samp)), 0, eve_id]\n",
    "        new_events.append(eve)\n",
    "    \n",
    "    ch_name = 'ICA'\n",
    "    if ch_name not in raw_filt.info['ch_names']:\n",
    "        stim_data = np.zeros((1, len(raw_filt.times)))\n",
    "        info_sp = mne.create_info([ch_name], raw_filt.info['sfreq'], ['stim'])\n",
    "        stim_sp = mne.io.RawArray(stim_data, info_sp, verbose=False)\n",
    "        raw_filt.add_channels([stim_sp], force_update_info=True)\n",
    "\n",
    "    raw_filt.add_events(new_events, stim_channel=ch_name, replace=True)\n",
    "    events= mne.find_events(raw_filt, stim_channel=ch_name, verbose=False)\n",
    "    event_id = {eve_name: eve_id}\n",
    "    picks = mne.pick_types(raw_filt.info, meg=picks_raw, eeg=False, eog=False)\n",
    "    epochs = mne.Epochs(raw_filt, events, event_id,  tmin, tmax, baseline=None, picks=picks, preload=True, verbose=False)\n",
    "    return epochs\n",
    "    del raw_filt, picks, event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "block1 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block001_ICA_based_grad.mat')\n",
    "\n",
    "block2 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block002_ICA_based_grad.mat')\n",
    "block2['spikeind'][0,:] += 600_000\n",
    "spikes = block1['spikeind'][0,:].tolist() + block2['spikeind'][0,:].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-6b2eabb860f9>:2: RuntimeWarning: This filename (/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz or raw_tsss.fif.gz\n",
      "  data = mne.io.read_raw_fif(tsss_file, preload=False, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-6b2eabb860f9>:4: RuntimeWarning: This filename (/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs.save(\"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif\", overwrite=True)\n"
     ]
    }
   ],
   "source": [
    "tsss_file = \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "data = mne.io.read_raw_fif(tsss_file, preload=False, verbose=False)\n",
    "epochs = create_epochs(data, spikes, tmin=-0.5, tmax=0.5, picks_raw=True)\n",
    "epochs.save(\"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif\", overwrite=True)\n",
    "\n",
    "raw_data = epochs.pick_types(meg=True, eeg=False,stim=False, eog=False).get_data()\n",
    "raw_data_reshaped = raw_data.transpose(1,0,2).reshape(raw_data.shape[1],-1)\n",
    "\n",
    "npy_file = \"/Users/valery/MEG/Cases/B1C2/Spyking_circus/B1C2_B1C2_ii_run1_raw_tsss_mc_art_corr/only_epochs/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "np.save(\"%s_0.npy\"%(npy_file[:-4]), (raw_data_reshaped).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib qt5\n",
    "%matplotlib qt5\n",
    "\n",
    "epochs.plot(n_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsss_file = \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "#data = mne.io.read_raw_fif(tsss_file, preload=True, verbose=False)\n",
    "\n",
    "#raw_data = data.pick_types(meg=True, eeg=False,stim=False, eog=False).get_data()\n",
    "#tsss_file = \"/Users/valery/MEG/Cases/B1C2/Spyking_circus/B1C2_B1C2_ii_run1_raw_tsss_mc_art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "#np.save(\"%s_1.npy\"%(tsss_file[:-4]), (raw_data).astype(float))\n",
    "\n",
    "#raw_data = epochs.pick_types(meg=True, eeg=False,stim=False, eog=False).get_data()\n",
    "#tsss_file = \"/Users/valery/MEG/Cases/B1C2/Spyking_circus/B1C2_B1C2_ii_run1_raw_tsss_mc_art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "#np.save(\"%s_0.npy\"%(tsss_file[:-4]), (raw_data).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "778 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-f7540aaee048>:3: RuntimeWarning: This filename (/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs = mne.read_epochs(\"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif\", preload=False)\n"
     ]
    }
   ],
   "source": [
    "#tsss_file = \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif\"\n",
    "import mne\n",
    "epochs = mne.read_epochs(\"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif\", preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: /Users/valery/MEG/Cases/B1C2/Spyking_circus/B1C2_B1C2_ii_run1_raw_tsss_mc_art_corr/\n",
      "File: B1C2_ii_run1_raw_tsss_mc_art_corr_0.npy\n",
      "Parameters: N_t = 450, Cut off = 9, Threshold = 6.0, cc_merge = 0.97\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:15ex; max-width:15ex; vertical-align:middle; text-align:right\">Sensors </span>\n",
       "<progress style=\"width:45ex\" max=\"1\" value=\"1\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">1/1</span>\n",
       "<span class=\"Time-label\">[00:02<00:02, 2.09s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       "       Sensors  [█████████████████████████████████████████████] 1/1 [00:02<00:02, 2.09s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:15ex; max-width:15ex; vertical-align:middle; text-align:right\">Templates </span>\n",
       "<progress style=\"width:45ex\" max=\"8\" value=\"8\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">8/8</span>\n",
       "<span class=\"Time-label\">[03:14<00:21, 24.20s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       "     Templates  [█████████████████████████████████████████████] 8/8 [03:14<00:21, 24.20s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import run_circus_ASPIRE as run_circus\n",
    "import scipy.io\n",
    "import circus_templates_ASPIRE as circus_templates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import traceback\n",
    "import shutil\n",
    "dir_case = \"/Users/valery/MEG/Cases/B1C2/\"\n",
    "dir_SPC = dir_case + \"Spyking_circus/B1C2_B1C2_ii_run1_raw_tsss_mc_art_corr/\"\n",
    "SPC_fname = \"B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "nmpy_file = 'B1C2_ii_run1_raw_tsss_mc_art_corr_0.npy'\n",
    "epochs_fname = dir_case +  \"art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif\"\n",
    "for n_t in [450]:\n",
    "    for mad in [6.0]:\n",
    "        try:\n",
    "            #shutil.copy(dir_SPC +'full_case/' + nmpy_file, dir_SPC)\n",
    "            #sc = run_circus.Circus(dir_case, \"B1C2\", dir_SPC, SPC_fname, N_t=n_t, cc_merge=0.97, MAD=mad, cut_off=9)\n",
    "            #sc.params_iterations(run_spc=True, only_fitting = False, sensors=['grad'])\n",
    "            \n",
    "            #shutil.copy(dir_SPC +'only_epochs/' + nmpy_file, dir_SPC)\n",
    "            sc = run_circus.Circus(dir_case, \"B1C2\", dir_SPC, SPC_fname, N_t=n_t, cc_merge=0.97, MAD=mad, cut_off=9)\n",
    "            sc.params_iterations(run_spc=False, only_fitting = True, sensors=['grad'])\n",
    "\n",
    "            for sens in ['grad']:\n",
    "                temp = circus_templates.Templates(dir_case, \"B1C2\", SPC_fname, sc.sensors_params[sens], sensors=sens, n_sp=3, N_t=n_t, cc_merge=0.97, MAD=mad)\n",
    "                temp.plot_all_templates(epochs_fname, 'Mac')\n",
    "        except Exception: traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "evocked_0 = epochs[6].load_data().pick_types(meg='grad').filter(1., 45., fir_design='firwin').average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\", line 216, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/mne/viz/topo.py\", line 278, in _plot_topo_onpick\n",
      "    show_func(ax, ch_idx)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/mne/viz/topo.py\", line 455, in _plot_timeseries\n",
      "    linestyle='--')\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 2418, in axvline\n",
      "    return gca().axvline(x=x, ymin=ymin, ymax=ymax, **kwargs)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/axes/_axes.py\", line 931, in axvline\n",
      "    scalex = (xx < xmin) or (xx > xmax)\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\", line 216, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/mne/viz/topo.py\", line 278, in _plot_topo_onpick\n",
      "    show_func(ax, ch_idx)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/mne/viz/topo.py\", line 455, in _plot_timeseries\n",
      "    linestyle='--')\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 2418, in axvline\n",
      "    return gca().axvline(x=x, ymin=ymin, ymax=ymax, **kwargs)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/axes/_axes.py\", line 931, in axvline\n",
      "    scalex = (xx < xmin) or (xx > xmax)\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\", line 216, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/mne/viz/topo.py\", line 278, in _plot_topo_onpick\n",
      "    show_func(ax, ch_idx)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/mne/viz/topo.py\", line 455, in _plot_timeseries\n",
      "    linestyle='--')\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 2418, in axvline\n",
      "    return gca().axvline(x=x, ymin=ymin, ymax=ymax, **kwargs)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/axes/_axes.py\", line 931, in axvline\n",
      "    scalex = (xx < xmin) or (xx > xmax)\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\", line 216, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/mne/viz/topo.py\", line 278, in _plot_topo_onpick\n",
      "    show_func(ax, ch_idx)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/mne/viz/topo.py\", line 455, in _plot_timeseries\n",
      "    linestyle='--')\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 2418, in axvline\n",
      "    return gca().axvline(x=x, ymin=ymin, ymax=ymax, **kwargs)\n",
      "  File \"/anaconda3/envs/mne/lib/python3.6/site-packages/matplotlib/axes/_axes.py\", line 931, in axvline\n",
      "    scalex = (xx < xmin) or (xx > xmax)\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%matplotlib qt5\n",
    "%matplotlib qt5\n",
    "ch, t = evocked_0.get_peak(tmin=-0.2,tmax=0.2)\n",
    "evocked_0.plot_topo(vline=[t,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.075"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evocked_0.get_peak(tmin=-0.2,tmax=0.2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = temp.templates[abs(temp.templates.Amplitudes-1)<0.01]\n",
    "best.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = best[best.Template == 'temp_0'].Time.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 1 events and 1001 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<EpochsFIF  |   1 events (all good), -0.4 - 0 sec, baseline off, ~6.5 MB, data loaded,\n",
       " 'ICA_det': 1>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs[0].load_data().crop(-0.4,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40160,     0,     1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs[0].events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124061, 283648, 534692, 654508, 714074]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib qt5\n",
    "%matplotlib qt5\n",
    "\n",
    "\n",
    "plot_sensors = 'grad' # 'mag', 'grad' or True (all sensors)\n",
    "window = 10 #in seconds\n",
    "start = 0.0 #start point in seconds\n",
    "\n",
    "block1 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block001_ICA_based_grad.mat')\n",
    "\n",
    "block2 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block002_ICA_based_grad.mat')\n",
    "block2['spikeind'][0,:] += 600_000\n",
    "spikes = block1['spikeind'][0,:].tolist() + block2['spikeind'][0,:].tolist()\n",
    "\n",
    "#tsss_file = \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif\"\n",
    "#data = mne.io.read_raw_fif(tsss_file, preload=True, verbose=False)\n",
    "#data.pick_types(meg=plot_sensors, eeg=False,stim=False,eog=False,ecg=False,emg=False,misc=False)\n",
    "\n",
    "data = mne.io.read_raw_fif( \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\", preload=True, verbose=False)\n",
    "data.pick_types(meg=plot_sensors, eeg=False,stim=False,eog=False,ecg=False,emg=False,misc=False)\n",
    "\n",
    "onset = temp.templates['Spiketimes']/1000 + data.first_samp/1000\n",
    "data.annotations.append(onset, np.repeat(0.00001, len(onset)), temp.templates['Template'].tolist())\n",
    "\n",
    "onset = [(data.first_samp+i)/1000 for i in spikes]\n",
    "data.annotations.append(onset, np.repeat(0.00001, len(onset)), [' ']*len(onset))\n",
    "\n",
    "#onset = [data.first_samp/1000 + i*0.4 +0.2  for i in range(len(spikes))]\n",
    "#data.annotations.append(onset, np.repeat(0.00001, len(onset)), [' ']*len(onset))\n",
    "\n",
    "data.plot(duration=window, group_by='position', start=start, lowpass=45, highpass=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = np.load(dir_SPC +'only_epochs/' + nmpy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 1 events and 1001 original time points ...\n"
     ]
    }
   ],
   "source": [
    "eppp = epochs[1].get_data()[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(306) if (ep[i,1002]-eppp[i,1]) != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 10 events and 1001 original time points ...\n"
     ]
    }
   ],
   "source": [
    "epp = epochs[0:10].get_data()[0:10,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 778 events and 2001 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(778, 306, 2001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eppp = epp.reshape(306,10010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 1 events and 1001 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.235066159908211e-12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), array([4, 5, 6]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[[1,2,3], \n",
    "               [4,5,6]],\n",
    "              [[7,8,9], \n",
    "               [10,11,12]]])\n",
    "\n",
    "(a[0,0,:],a[0,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  7,  8,  9],\n",
       "       [ 4,  5,  6, 10, 11, 12]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(1,0,2).reshape(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "a.reshape(shape, order='C')\n",
       "\n",
       "Returns an array containing the same data with a new shape.\n",
       "\n",
       "Refer to `numpy.reshape` for full documentation.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "numpy.reshape : equivalent function\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Unlike the free function `numpy.reshape`, this method on `ndarray` allows\n",
       "the elements of the shape parameter to be passed in as separate arguments.\n",
       "For example, ``a.reshape(10, 11)`` is equivalent to\n",
       "``a.reshape((10, 11))``.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.reshape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
