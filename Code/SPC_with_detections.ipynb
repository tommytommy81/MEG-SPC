{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epochs(raw_filt, detections, tmin=-1, tmax=1, picks_raw=True, no_first_sample=False):\n",
    "    \"\"\" Here we create epochs for events\"\"\"\n",
    "    import mne\n",
    "    import numpy as np\n",
    "    eve_id = 1\n",
    "    eve_name = 'ICA_det'\n",
    "    \n",
    "\n",
    "    raw_filt.load_data()\n",
    "    \n",
    "    new_events, eve = [], []\n",
    "    if no_first_sample:\n",
    "        first_samp = 0\n",
    "    else:\n",
    "        first_samp = raw_filt.first_samp\n",
    "    \n",
    "    for spike_time in detections:\n",
    "        eve = [int(round(spike_time + first_samp)), 0, eve_id]\n",
    "        new_events.append(eve)\n",
    "    \n",
    "    ch_name = 'ICA'\n",
    "    if ch_name not in raw_filt.info['ch_names']:\n",
    "        stim_data = np.zeros((1, len(raw_filt.times)))\n",
    "        info_sp = mne.create_info([ch_name], raw_filt.info['sfreq'], ['stim'])\n",
    "        stim_sp = mne.io.RawArray(stim_data, info_sp, verbose=False)\n",
    "        raw_filt.add_channels([stim_sp], force_update_info=True)\n",
    "\n",
    "    raw_filt.add_events(new_events, stim_channel=ch_name, replace=True)\n",
    "    events= mne.find_events(raw_filt, stim_channel=ch_name, verbose=False)\n",
    "    event_id = {eve_name: eve_id}\n",
    "    picks = mne.pick_types(raw_filt.info, meg=picks_raw, eeg=False, eog=False)\n",
    "    epochs = mne.Epochs(raw_filt, events, event_id,  tmin, tmax, baseline=None, picks=picks, preload=True, verbose=False)\n",
    "    return epochs\n",
    "    del raw_filt, picks, event_id\n",
    "    \n",
    "def find_nearest(array, value):\n",
    "    import numpy as np\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "def plot_topomap(temp_evocked, evocked, svg_path, temp_n, time, amplitude, one_spike=False, diff=0):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mne.viz import plot_evoked_topo\n",
    "    \n",
    "    colors = 'blue','red'\n",
    "    evocked.data = evocked.data*10**13\n",
    "    temp_evocked.data = temp_evocked.data*10**4.5\n",
    "    temp_evocked.times = np.linspace(-0.050,0.050,101) + diff\n",
    "    fig = plot_evoked_topo([evocked,temp_evocked], color=colors, background_color='w',legend=False)\n",
    "    fig.set_figheight(fig.get_figwidth()*1.5)\n",
    "    fig.set_figwidth(fig.get_figheight()*1.5)\n",
    "    if not one_spike:\n",
    "        fig.suptitle('Template %s\\nSpike time: avarage of %s event(s)\\nGoodness of fit (average): %s'%(temp_n, evocked.nave, amplitude), x=0.42)\n",
    "    else:\n",
    "        fig.suptitle('Template %s\\nSpike time: %ss\\nGoodness of fit: %s'%(temp_n, time/1000, amplitude), x=0.42)\n",
    "        temp.one_spike_name = \"spike_%s_templates_topo_%s\"%(time,temp_n)\n",
    "    \n",
    "    fname = \"%s/spike_%s_templates_topo_%s.svg\"%(svg_path,time,temp_n)\n",
    "    fig.savefig(fname, format='svg', papertype='legal')\n",
    "    \n",
    "    temp.templates_topo_temp_n_path = fname\n",
    "    \n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "def plot_joint(evocked):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import mne\n",
    "    fig = mne.viz.plot_evoked_joint(evocked, times = np.array([-0.2, -0.1, -0.05, 0.0, 0.05, 0.1, 0.2]), show=False)\n",
    "    #fig.set_figheight(fig.get_figwidth()*1.05)\n",
    "    #fig.set_figwidth(fig.get_figheight()*1.05)\n",
    "    fname = \"%s%s_evoked_joint_grad.svg\"%(temp.svg_path, temp.temp_n)\n",
    "    plt.savefig(fname, format='svg', papertype='legal')\n",
    "\n",
    "    temp.plot_evoked_joint_temp_n_grad_path = fname\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_epoch_image(epochs):\n",
    "    import mne\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = epochs.plot_image()\n",
    "    fname = \"%s%s_epochs_image.svg\"%(temp.svg_path, temp.temp_n)\n",
    "\n",
    "    fig[0].savefig(fname, format='svg', papertype='legal')\n",
    "    temp.plot_epochs_image_temp_n_path = fname\n",
    "    \n",
    "def plot_final_temp_n(temp, one_spike=False, system_type='Mac'):\n",
    "    \"\"\" Plot all plots in one\"\"\"\n",
    "    import svgutils.transform as sg\n",
    "    from subprocess import Popen\n",
    "    import os\n",
    "    \n",
    "    fig = sg.SVGFigure(\"22cm\", \"24cm\")\n",
    "    plot1 = sg.fromfile(temp.templates_topo_temp_n_path).getroot()\n",
    "    #plot1 = sg.from_mpl(temp.templates_topo_temp_n_fig).getroot()\n",
    "    plot1.moveto(0, 0)\n",
    "    plot2 = sg.fromfile(temp.plot_evoked_joint_temp_n_grad_path).getroot()\n",
    "    #plot2 = sg.from_mpl(temp.plot_evoked_joint_temp_n_grad_fig).getroot()\n",
    "    plot2.moveto(30, 650)\n",
    "    plot2.scale_xy(0.7, 0.7)\n",
    "    \n",
    "    plot3 = sg.fromfile(temp.plot_epochs_image_temp_n_path).getroot()\n",
    "    plot3.moveto(450, 650)\n",
    "    plot3.scale_xy(0.7, 0.7)\n",
    "    \n",
    "    l = []\n",
    "    l.append(sg.TextElement(50,50, \"A\", size=12, weight=\"bold\"))\n",
    "    l.append(sg.TextElement(50,650, \"B\", size=12, weight=\"bold\"))\n",
    "    l.append(sg.TextElement(450,650, \"C\", size=12, weight=\"bold\"))\n",
    "    \n",
    "    fig.append([plot1, plot2, plot3])\n",
    "    fig.append(l)\n",
    "    fig.save(\"%s%s_fig_final.svg\"%(temp.svg_path, temp.temp_n))\n",
    "    \n",
    "    your_svg_input = \"%s%s_fig_final.svg\"%(temp.svg_path, temp.temp_n)\n",
    "    \n",
    "    if not one_spike:\n",
    "        your_png_output = \"%s%s_temp.png\"%(temp.png_path, temp.temp_n)\n",
    "    else:\n",
    "        os.makedirs(\"{}{}_temp\".format(temp.png_path, temp.temp_n),exist_ok=True)\n",
    "        your_png_output = \"{}{}_temp/{}.png\".format(temp.png_path, temp.temp_n,temp.one_spike_name)\n",
    "\n",
    "    if system_type == 'Mac':\n",
    "        x = Popen(['/Applications/Inkscape.app/Contents/Resources/bin/inkscape', your_svg_input, \\\n",
    "                   '--export-png=%s' % your_png_output, '-w3000 -h4500', '-b white'])\n",
    "    elif system_type == 'Windows':\n",
    "        x = Popen(['C:/Program Files/Inkscape/inkscape', your_svg_input, \\\n",
    "                   '--export-png=%s' % your_png_output, '-w2000 -h3000', '-b white'])\n",
    "    #try:\n",
    "    #    Templates._waitForResponse(x)\n",
    "    #except OSError:\n",
    "    #    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import scipy.io\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "block1 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block001_ICA_based_grad.mat')\n",
    "\n",
    "block2 = scipy.io.loadmat('/Users/valery/MEG/Cases/B1C2/ASPIRE/results/\\\n",
    "sources_B1C2_ii_run1_raw_tsss_mc_art_corr_data_\\\n",
    "block002_ICA_based_grad.mat')\n",
    "block2['spikeind'][0,:] += 600_000\n",
    "spikes = block1['spikeind'][0,:].tolist() + block2['spikeind'][0,:].tolist()\n",
    "\n",
    "tsss_file = \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "data = mne.io.read_raw_fif(tsss_file, preload=False, verbose=False)\n",
    "#epochs = create_epochs(data, spikes, tmin=-0.2, tmax=0.2, picks_raw=True)\n",
    "\n",
    "#aligned_spikes = [epochs[i].events.tolist()[0][0]+\\\n",
    "#                  epochs[i].load_data().pick_types(meg='grad').filter(9.,100.).average().get_peak()[1]\\\n",
    "#                  for i in range(len(epochs))]\n",
    "aligned_spikes = [i+data.first_samp for i in spikes]\n",
    "results = pd.DataFrame(data=zip(spikes,aligned_spikes),columns=[\"Spikes\",\"Aligned_spikes\"])\n",
    "results.to_excel(\"/Users/valery/MEG/Cases/B1C2/results.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_circus_ASPIRE as run_circus\n",
    "import scipy.io\n",
    "import circus_templates_ASPIRE as circus_templates\n",
    "import mne\n",
    "import traceback\n",
    "import shutil\n",
    "\n",
    "dir_case = \"/Users/valery/MEG/Cases/B1C2/\"\n",
    "dir_SPC = dir_case + \"Spyking_circus/B1C2_B1C2_ii_run1_raw_tsss_mc_art_corr/\"\n",
    "SPC_fname = \"B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "nmpy_file = 'B1C2_ii_run1_raw_tsss_mc_art_corr_0.npy'\n",
    "epochs_fname = dir_case +  \"art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr_epochs.fif\"\n",
    "n_t = 100\n",
    "\n",
    "for cc_merge in [0.3]:\n",
    "    for mad in [7.0]:\n",
    "        try:\n",
    "            #shutil.copy(dir_SPC +'full_case/' + nmpy_file, dir_SPC)\n",
    "            sc = run_circus.Circus(dir_case, \"B1C2\", dir_SPC, SPC_fname, N_t=n_t, cc_merge=cc_merge, MAD=mad, cut_off=3)\n",
    "            sc.params_iterations(run_spc=True, only_fitting = False, sensors=['grad'])\n",
    "            \n",
    "            #shutil.copy(dir_SPC +'only_epochs/' + nmpy_file, dir_SPC)\n",
    "            #sc = run_circus.Circus(dir_case, \"B1C2\", dir_SPC, SPC_fname, N_t=n_t, cc_merge=0.97, MAD=mad, cut_off=9)\n",
    "            #sc.params_iterations(run_spc=True, only_fitting = True, sensors=['grad'])\n",
    "\n",
    "            for sens in ['grad']:\n",
    "                temp = circus_templates.Templates(dir_case, \"B1C2\", SPC_fname, sc.sensors_params[sens], sensors=sens, n_sp=3, N_t=n_t, cc_merge=0.3, MAD=mad)\n",
    "                #temp.plot_all_templates(epochs_fname, 'Mac')\n",
    "        except Exception: traceback.print_exc()\n",
    "\n",
    "        try:    \n",
    "            ## Select fitted spikes from SPC that was fitted on the same peak\n",
    "            import pandas as pd\n",
    "            results = pd.read_excel(\"/Users/valery/MEG/Cases/B1C2/results.xlsx\")\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                around_spike = temp.templates[abs(temp.templates.Spiketimes-(results.Aligned_spikes[i]-39000))<100]\n",
    "                if not around_spike.empty:\n",
    "                    Amplitude =  find_nearest(around_spike.Amplitudes,1)\n",
    "                    Spiketime = temp.templates[temp.templates.Amplitudes==Amplitude].Spiketimes.tolist()[0]\n",
    "                    Template = temp.templates[temp.templates.Amplitudes==Amplitude].Template.tolist()[0]\n",
    "\n",
    "                    results.loc[i,'Difference'] = Spiketime - (results.Aligned_spikes[i]-39000)\n",
    "                    results.loc[i,'Template'] = temp.templates[temp.templates.Spiketimes==results.loc[i,'Difference']+(results.Aligned_spikes[i]-39000)].Template.tolist()[0]\n",
    "                    results.loc[i,'Template_n'] = int(results.loc[i,'Template'].split('_')[1])\n",
    "                    results.loc[i,'Amplitude'] = Amplitude\n",
    "\n",
    "        except Exception: traceback.print_exc()\n",
    "        try:\n",
    "            ## Plot average & individual spikes\n",
    "            import mne\n",
    "            import numpy as np\n",
    "\n",
    "            tsss_file = \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "            data = mne.io.read_raw_fif(tsss_file, preload=False, verbose=False)\n",
    "\n",
    "            godness_percentile = np.percentile(abs(results.dropna().Amplitude.to_numpy()-1),10) #10%\n",
    "            best_results = results[abs(results.Amplitude-1)<godness_percentile]\n",
    "\n",
    "            filter_value = (1.0,45.0)\n",
    "\n",
    "            for temp_n in best_results.Template_n.unique().tolist():\n",
    "                results_temp_n = best_results[best_results.Template_n == temp_n]\n",
    "                aligned_spikes = (results_temp_n.Aligned_spikes + results_temp_n.Difference).tolist()\n",
    "\n",
    "                epochs = create_epochs(data, aligned_spikes, tmin=-0.5, tmax=0.5, picks_raw=True,no_first_sample=True)\n",
    "\n",
    "                temp.data_info = epochs.info\n",
    "                temp.data_info_sens = epochs[0].load_data().pick_types(meg=temp.sensors, eeg=False,stim=False, eog=False).info\n",
    "                temp.temp_n = int(temp_n)\n",
    "\n",
    "                epochs.load_data().pick_types(meg=temp.sensors, eeg=False,stim=False, eog=False).filter(filter_value[0], filter_value[1], fir_design='firwin')\n",
    "                temp_evocked = temp.templates_topo_temp_n(return_temp=True)\n",
    "\n",
    "                ## Plot each spike\n",
    "                for i in range(len(epochs)):\n",
    "                    ep = epochs[i]\n",
    "                    time = ep.events[0][0]\n",
    "                    ev = ep.average()\n",
    "                    amplitude = results_temp_n.loc[(results_temp_n.Aligned_spikes+results_temp_n.Difference).round()==time,'Amplitude'].values[0]\n",
    "                    plot_epoch_image(epochs[i])\n",
    "                    temp_evocked = temp.templates_topo_temp_n(return_temp=True)\n",
    "                    plot_topomap(temp_evocked, ev, temp.svg_path, temp.temp_n, int(time), amplitude, one_spike=True)\n",
    "                    plot_joint(ev)\n",
    "                    plot_final_temp_n(temp, one_spike=True)\n",
    "\n",
    "                ## Plot average\n",
    "                temp_evocked = temp.templates_topo_temp_n(return_temp=True)\n",
    "                file_name = 'average_{}_spikes_filt_{}'.format(len(results_temp_n),filter_value)\n",
    "                plot_epoch_image(epochs)\n",
    "                evocked = epochs.average()\n",
    "\n",
    "                amplitude = results_temp_n.Amplitude.mean()   \n",
    "                plot_topomap(temp_evocked, evocked, temp.svg_path, temp.temp_n, file_name, amplitude)\n",
    "                plot_joint(evocked)\n",
    "\n",
    "                plot_final_temp_n(temp)\n",
    "\n",
    "            \n",
    "            results.to_excel(temp.waveforms_path + '/results.xlsx')\n",
    "        except Exception: traceback.print_exc()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select fitted spikes from SPC that was fitted on the same peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "results = pd.read_excel(\"/Users/valery/MEG/Cases/B1C2/results.xlsx\")\n",
    "\n",
    "for i in range(len(results)):\n",
    "    around_spike = temp.templates[abs(temp.templates.Spiketimes-(results.Aligned_spikes[i]-39000))<100]\n",
    "    if not around_spike.empty:\n",
    "        Amplitude =  find_nearest(around_spike.Amplitudes,1)\n",
    "        Spiketime = temp.templates[temp.templates.Amplitudes==Amplitude].Spiketimes.tolist()[0]\n",
    "        Template = temp.templates[temp.templates.Amplitudes==Amplitude].Template.tolist()[0]\n",
    "\n",
    "        results.loc[i,'Difference'] = Spiketime - (results.Aligned_spikes[i]-39000)\n",
    "        results.loc[i,'Template'] = temp.templates[temp.templates.Spiketimes==results.loc[i,'Difference']+(results.Aligned_spikes[i]-39000)].Template.tolist()[0]\n",
    "        results.loc[i,'Template_n'] = int(results.loc[i,'Template'].split('_')[1])\n",
    "        results.loc[i,'Amplitude'] = Amplitude\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot average & individual spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "godness_percentile = np.percentile(abs(results.dropna().Amplitude.to_numpy()-1),10) #10%\n",
    "tsss_file = \"/Users/valery/MEG/Cases/B1C2/art_corr/B1C2_ii_run1_raw_tsss_mc_art_corr.fif\"\n",
    "data = mne.io.read_raw_fif(tsss_file, preload=False, verbose=False)\n",
    "best_results = results[abs(results.Amplitude-1)<godness_percentile]\n",
    "filter_value = (1.0,45.0)\n",
    "\n",
    "for temp_n in best_results.Template_n.unique().tolist():\n",
    "    results_temp_n = best_results[best_results.Template_n == temp_n]\n",
    "    aligned_spikes = (results_temp_n.Aligned_spikes + results_temp_n.Difference).tolist()\n",
    "    \n",
    "    epochs = create_epochs(data, aligned_spikes, tmin=-0.5, tmax=0.5, picks_raw=True,no_first_sample=True)\n",
    "    \n",
    "    temp.data_info = epochs.info\n",
    "    temp.data_info_sens = epochs[0].load_data().pick_types(meg=temp.sensors, eeg=False,stim=False, eog=False).info\n",
    "    temp.temp_n = int(temp_n)\n",
    "    \n",
    "    epochs.load_data().pick_types(meg=temp.sensors, eeg=False,stim=False, eog=False).filter(filter_value[0], filter_value[1], fir_design='firwin')\n",
    "    temp_evocked = temp.templates_topo_temp_n(return_temp=True)\n",
    "    \n",
    "    ## Plot each spike\n",
    "    for i in range(len(epochs)):\n",
    "        ep = epochs[i]\n",
    "        time = ep.events[0][0]\n",
    "        ev = ep.average()\n",
    "        amplitude = results_temp_n.loc[(results_temp_n.Aligned_spikes+results_temp_n.Difference).round()==time,'Amplitude'].values[0]\n",
    "        plot_epoch_image(epochs[i])\n",
    "        temp_evocked = temp.templates_topo_temp_n(return_temp=True)\n",
    "        plot_topomap(temp_evocked, ev, temp.svg_path, temp.temp_n, int(time), amplitude, one_spike=True)\n",
    "        plot_joint(ev)\n",
    "        plot_final_temp_n(temp, one_spike=True)\n",
    "        \n",
    "    ## Plot average\n",
    "    temp_evocked = temp.templates_topo_temp_n(return_temp=True)\n",
    "    file_name = 'average_{}_spikes_filt_{}'.format(len(results_temp_n),filter_value)\n",
    "    plot_epoch_image(epochs)\n",
    "    evocked = epochs.average()\n",
    "    \n",
    "    amplitude = results_temp_n.Amplitude.mean()   \n",
    "    plot_topomap(temp_evocked, evocked, temp.svg_path, temp.temp_n, file_name, amplitude)\n",
    "    plot_joint(evocked)\n",
    "    \n",
    "    plot_final_temp_n(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
